{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request https://realpython.github.io/fake-jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "soup = BS(response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the tag containing the first job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Python Developer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract **all** job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Python Developer',\n",
       " 'Energy engineer',\n",
       " 'Legal executive',\n",
       " 'Fitness centre manager',\n",
       " 'Product manager',\n",
       " 'Medical technical officer',\n",
       " 'Physiological scientist',\n",
       " 'Textile designer',\n",
       " 'Television floor manager',\n",
       " 'Waste management officer',\n",
       " 'Software Engineer (Python)',\n",
       " 'Interpreter',\n",
       " 'Architect',\n",
       " 'Meteorologist',\n",
       " 'Audiological scientist',\n",
       " 'English as a second language teacher',\n",
       " 'Surgeon',\n",
       " 'Equities trader',\n",
       " 'Newspaper journalist',\n",
       " 'Materials engineer',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Product/process development scientist',\n",
       " 'Scientist, research (maths)',\n",
       " 'Ecologist',\n",
       " 'Materials engineer',\n",
       " 'Historic buildings inspector/conservation officer',\n",
       " 'Data scientist',\n",
       " 'Psychiatrist',\n",
       " 'Structural engineer',\n",
       " 'Immigration officer',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Neurosurgeon',\n",
       " 'Broadcast engineer',\n",
       " 'Make',\n",
       " 'Nurse, adult',\n",
       " 'Air broker',\n",
       " 'Editor, film/video',\n",
       " 'Production assistant, radio',\n",
       " 'Engineer, communications',\n",
       " 'Sales executive',\n",
       " 'Software Developer (Python)',\n",
       " 'Futures trader',\n",
       " 'Tour manager',\n",
       " 'Cytogeneticist',\n",
       " 'Designer, multimedia',\n",
       " 'Trade union research officer',\n",
       " 'Chemist, analytical',\n",
       " 'Programmer, multimedia',\n",
       " 'Engineer, broadcasting (operations)',\n",
       " 'Teacher, primary school',\n",
       " 'Python Developer',\n",
       " 'Manufacturing systems engineer',\n",
       " 'Producer, television/film/video',\n",
       " 'Scientist, forensic',\n",
       " 'Bonds trader',\n",
       " 'Editorial assistant',\n",
       " 'Photographer',\n",
       " 'Retail banker',\n",
       " 'Jewellery designer',\n",
       " 'Ophthalmologist',\n",
       " 'Back-End Web Developer (Python, Django)',\n",
       " 'Licensed conveyancer',\n",
       " 'Futures trader',\n",
       " 'Counselling psychologist',\n",
       " 'Insurance underwriter',\n",
       " 'Engineer, automotive',\n",
       " 'Producer, radio',\n",
       " 'Dispensing optician',\n",
       " 'Designer, fashion/clothing',\n",
       " 'Chartered loss adjuster',\n",
       " 'Back-End Web Developer (Python, Django)',\n",
       " 'Forest/woodland manager',\n",
       " 'Clinical cytogeneticist',\n",
       " 'Print production planner',\n",
       " 'Systems developer',\n",
       " 'Graphic designer',\n",
       " 'Writer',\n",
       " 'Field seismologist',\n",
       " 'Chief Strategy Officer',\n",
       " 'Air cabin crew',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Warden/ranger',\n",
       " 'Sports therapist',\n",
       " 'Arts development officer',\n",
       " 'Printmaker',\n",
       " 'Health and safety adviser',\n",
       " 'Manufacturing systems engineer',\n",
       " 'Programmer, applications',\n",
       " 'Medical physicist',\n",
       " 'Media planner',\n",
       " 'Software Developer (Python)',\n",
       " 'Surveyor, land/geomatics',\n",
       " 'Legal executive',\n",
       " 'Librarian, academic',\n",
       " 'Barrister',\n",
       " 'Museum/gallery exhibitions officer',\n",
       " 'Radiographer, diagnostic',\n",
       " 'Database administrator',\n",
       " 'Furniture designer',\n",
       " 'Ship broker']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull all titles\n",
    "all_titles = soup.findAll('h2')\n",
    "\n",
    "# Create list of all titles as text\n",
    "job_title = [x.text for x in all_titles]\n",
    "    \n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get companies, locations, and posting dates for each job into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Payne, Roberts and Davis',\n",
       " 'Vasquez-Davidson',\n",
       " 'Jackson, Chambers and Levy',\n",
       " 'Savage-Bradley',\n",
       " 'Ramirez Inc',\n",
       " 'Rogers-Yates',\n",
       " 'Kramer-Klein',\n",
       " 'Meyers-Johnson',\n",
       " 'Hughes-Williams',\n",
       " 'Jones, Williams and Villa',\n",
       " 'Garcia PLC',\n",
       " 'Gregory and Sons',\n",
       " 'Clark, Garcia and Sosa',\n",
       " 'Bush PLC',\n",
       " 'Salazar-Meyers',\n",
       " 'Parker, Murphy and Brooks',\n",
       " 'Cruz-Brown',\n",
       " 'Macdonald-Ferguson',\n",
       " 'Williams, Peterson and Rojas',\n",
       " 'Smith and Sons',\n",
       " 'Moss, Duncan and Allen',\n",
       " 'Gomez-Carroll',\n",
       " 'Manning, Welch and Herring',\n",
       " 'Lee, Gutierrez and Brown',\n",
       " 'Davis, Serrano and Cook',\n",
       " 'Smith LLC',\n",
       " 'Thomas Group',\n",
       " 'Silva-King',\n",
       " 'Pierce-Long',\n",
       " 'Walker-Simpson',\n",
       " 'Cooper and Sons',\n",
       " 'Donovan, Gonzalez and Figueroa',\n",
       " 'Morgan, Butler and Bennett',\n",
       " 'Snyder-Lee',\n",
       " 'Harris PLC',\n",
       " 'Washington PLC',\n",
       " 'Brown, Price and Campbell',\n",
       " 'Mcgee PLC',\n",
       " 'Dixon Inc',\n",
       " 'Thompson, Sheppard and Ward',\n",
       " 'Adams-Brewer',\n",
       " 'Schneider-Brady',\n",
       " 'Gonzales-Frank',\n",
       " 'Smith-Wong',\n",
       " 'Pierce-Herrera',\n",
       " 'Aguilar, Rivera and Quinn',\n",
       " 'Lowe, Barnes and Thomas',\n",
       " 'Lewis, Gonzalez and Vasquez',\n",
       " 'Taylor PLC',\n",
       " 'Oliver, Jones and Ramirez',\n",
       " 'Rivera and Sons',\n",
       " 'Garcia PLC',\n",
       " 'Johnson, Wells and Kramer',\n",
       " 'Gonzalez LLC',\n",
       " 'Morgan, White and Macdonald',\n",
       " 'Robinson-Fitzpatrick',\n",
       " 'Waters, Wilson and Hoover',\n",
       " 'Hill LLC',\n",
       " 'Li-Gregory',\n",
       " 'Fisher, Ryan and Coleman',\n",
       " 'Stewart-Alexander',\n",
       " 'Abbott and Sons',\n",
       " 'Bryant, Santana and Davenport',\n",
       " 'Smith PLC',\n",
       " 'Patterson-Singh',\n",
       " 'Martinez-Berry',\n",
       " 'May, Taylor and Fisher',\n",
       " 'Bailey, Owen and Thompson',\n",
       " 'Vasquez Ltd',\n",
       " 'Leblanc LLC',\n",
       " 'Jackson, Ali and Mckee',\n",
       " 'Blankenship, Knight and Powell',\n",
       " 'Patton, Haynes and Jones',\n",
       " 'Wood Inc',\n",
       " 'Collins Group',\n",
       " 'Flores-Nelson',\n",
       " 'Mitchell, Jones and Olson',\n",
       " 'Howard Group',\n",
       " 'Kramer-Edwards',\n",
       " 'Berry-Houston',\n",
       " 'Mathews Inc',\n",
       " 'Riley-Johnson',\n",
       " 'Spencer and Sons',\n",
       " 'Camacho-Sanchez',\n",
       " 'Oliver and Sons',\n",
       " 'Eaton PLC',\n",
       " 'Stanley-Frederick',\n",
       " 'Bradley LLC',\n",
       " 'Parker, Goodwin and Zavala',\n",
       " 'Kim-Miles',\n",
       " 'Moreno-Rodriguez',\n",
       " 'Brown-Ortiz',\n",
       " 'Hartman PLC',\n",
       " 'Brooks Inc',\n",
       " 'Washington-Castillo',\n",
       " 'Nguyen, Yoder and Petty',\n",
       " 'Holder LLC',\n",
       " 'Yates-Ferguson',\n",
       " 'Ortega-Lawrence',\n",
       " 'Fuentes, Walls and Castro']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_companies = soup.findAll('h3')\n",
    "\n",
    "company = [x.text for x in all_companies]\n",
    "\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stewartbury, AA',\n",
       " 'Christopherville, AA',\n",
       " 'Port Ericaburgh, AA',\n",
       " 'East Seanview, AP',\n",
       " 'North Jamieview, AP',\n",
       " 'Davidville, AP',\n",
       " 'South Christopher, AE',\n",
       " 'Port Jonathan, AE',\n",
       " 'Osbornetown, AE',\n",
       " 'Scotttown, AP',\n",
       " 'Ericberg, AE',\n",
       " 'Ramireztown, AE',\n",
       " 'Figueroaview, AA',\n",
       " 'Kelseystad, AA',\n",
       " 'Williamsburgh, AE',\n",
       " 'Mitchellburgh, AE',\n",
       " 'West Jessicabury, AA',\n",
       " 'Maloneshire, AE',\n",
       " 'Johnsonton, AA',\n",
       " 'South Davidtown, AP',\n",
       " 'Port Sara, AE',\n",
       " 'Marktown, AA',\n",
       " 'Laurenland, AE',\n",
       " 'Lauraton, AP',\n",
       " 'South Tammyberg, AP',\n",
       " 'North Brandonville, AP',\n",
       " 'Port Robertfurt, AA',\n",
       " 'Burnettbury, AE',\n",
       " 'Herbertside, AA',\n",
       " 'Christopherport, AP',\n",
       " 'West Victor, AE',\n",
       " 'Port Aaron, AP',\n",
       " 'Loribury, AA',\n",
       " 'Angelastad, AP',\n",
       " 'Larrytown, AE',\n",
       " 'West Colin, AP',\n",
       " 'West Stephanie, AP',\n",
       " 'Laurentown, AP',\n",
       " 'Wrightberg, AP',\n",
       " 'Alberttown, AE',\n",
       " 'Brockburgh, AE',\n",
       " 'North Jason, AE',\n",
       " 'Arnoldhaven, AE',\n",
       " 'Lake Destiny, AP',\n",
       " 'South Timothyburgh, AP',\n",
       " 'New Jimmyton, AE',\n",
       " 'New Lucasbury, AP',\n",
       " 'Port Cory, AE',\n",
       " 'Gileston, AA',\n",
       " 'Cindyshire, AA',\n",
       " 'East Michaelfort, AA',\n",
       " 'Joybury, AE',\n",
       " 'Emmatown, AE',\n",
       " 'Colehaven, AP',\n",
       " 'Port Coryton, AE',\n",
       " 'Amyborough, AA',\n",
       " 'Reynoldsville, AA',\n",
       " 'Port Billy, AP',\n",
       " 'Adamburgh, AA',\n",
       " 'Wilsonmouth, AA',\n",
       " 'South Kimberly, AA',\n",
       " 'Benjaminland, AP',\n",
       " 'Zacharyport, AA',\n",
       " 'Port Devonville, AE',\n",
       " 'East Thomas, AE',\n",
       " 'New Jeffrey, AP',\n",
       " 'Davidside, AA',\n",
       " 'Jamesville, AA',\n",
       " 'New Kelly, AP',\n",
       " 'Lake Antonio, AA',\n",
       " 'New Elizabethside, AA',\n",
       " 'Millsbury, AE',\n",
       " 'Lloydton, AP',\n",
       " 'Port Jeremy, AA',\n",
       " 'New Elizabethtown, AA',\n",
       " 'Charlesstad, AE',\n",
       " 'Josephbury, AE',\n",
       " 'Seanfurt, AA',\n",
       " 'Williambury, AA',\n",
       " 'South Jorgeside, AP',\n",
       " 'Robertborough, AP',\n",
       " 'South Saratown, AP',\n",
       " 'Hullview, AA',\n",
       " 'Philipland, AP',\n",
       " 'North Patty, AE',\n",
       " 'North Stephen, AE',\n",
       " 'Stevensland, AP',\n",
       " 'Reyesstad, AE',\n",
       " 'Bellberg, AP',\n",
       " 'North Johnland, AE',\n",
       " 'Martinezburgh, AE',\n",
       " 'Joshuatown, AE',\n",
       " 'West Ericstad, AA',\n",
       " 'Tuckertown, AE',\n",
       " 'Perezton, AE',\n",
       " 'Lake Abigail, AE',\n",
       " 'Jacobshire, AP',\n",
       " 'Port Susan, AE',\n",
       " 'North Tiffany, AA',\n",
       " 'Michelleville, AP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_locations = soup.findAll('p', class_='location')\n",
    "\n",
    "location = [x.text.strip() for x in all_locations]\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_postings = soup.findAll('time')\n",
    "\n",
    "post_date = [x.text for x in all_postings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                     company              location  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
       "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
       "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
       "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
       "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
       "\n",
       "  posting_date  \n",
       "0   2021-04-08  \n",
       "1   2021-04-08  \n",
       "2   2021-04-08  \n",
       "3   2021-04-08  \n",
       "4   2021-04-08  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.DataFrame({'title': job_title, 'company': company, 'location': location, 'posting_date': post_date})\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column that includes the link to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                     company              location  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
       "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
       "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
       "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
       "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
       "\n",
       "  posting_date                                               link  \n",
       "0   2021-04-08  https://realpython.github.io/fake-jobs/jobs/se...  \n",
       "1   2021-04-08  https://realpython.github.io/fake-jobs/jobs/en...  \n",
       "2   2021-04-08  https://realpython.github.io/fake-jobs/jobs/le...  \n",
       "3   2021-04-08  https://realpython.github.io/fake-jobs/jobs/fi...  \n",
       "4   2021-04-08  https://realpython.github.io/fake-jobs/jobs/pr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_links = soup.findAll('a')\n",
    "# Also need to filter out the duplicate URL that appears every other entry.\n",
    "link = [apply_links[x].get('href') for x in range(1, len(apply_links), 2)]\n",
    "\n",
    "link\n",
    "\n",
    "jobs['link'] = link\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternate Solution** build the URLs from scratch.\n",
    "\n",
    "The URL strings follow the following convention:\n",
    "- https :// realpython.github.io / fake-jobs / jobs / <job_title_lowercase> <next_counter>.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get job descriptions from each posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with just the first posting to figure out where it's stored\n",
    "URL = 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('p')[1].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function to do the same thing, but with an argument for the URL to get **any** job description.<br>(Assuming the webpage is formatted the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the URLs have the same naming ocnvention:<br>- Website Name/'<br>- fake-jobs/<br>- job-title-all-lowercase-hyphenated<br>- -counter.html<br><br>Start by creating the first URL with a RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the job description from first posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "soup = BS(response.text)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p', 'class' == 'content').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function to pull the description paragraphs from each URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(URL):\n",
    "    response = requests.get(URL)\n",
    "    response.status_code\n",
    "    soup = BS(response.text)\n",
    "    print(soup.find('p', 'class' == 'content').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use .apply to run the function and get all the job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m URLs \u001b[38;5;241m=\u001b[39m jobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m----> 2\u001b[0m jobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [URLs\u001b[38;5;241m.\u001b[39mapply(get_desc(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m URLs]\n",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m URLs \u001b[38;5;241m=\u001b[39m jobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m----> 2\u001b[0m jobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [URLs\u001b[38;5;241m.\u001b[39mapply(get_desc(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m URLs]\n",
      "File \u001b[1;32mc:\\Users\\chabi\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\chabi\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\chabi\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\chabi\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "URLs = jobs['link'].squeeze()\n",
    "jobs['description'] = [URLs.apply(get_desc(x)) for x in URLs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
