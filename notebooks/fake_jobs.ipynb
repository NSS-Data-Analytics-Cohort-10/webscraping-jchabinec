{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request https://realpython.github.io/fake-jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the tag containing the first job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Python Developer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now extract **all** job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Python Developer',\n",
       " 'Energy engineer',\n",
       " 'Legal executive',\n",
       " 'Fitness centre manager',\n",
       " 'Product manager',\n",
       " 'Medical technical officer',\n",
       " 'Physiological scientist',\n",
       " 'Textile designer',\n",
       " 'Television floor manager',\n",
       " 'Waste management officer',\n",
       " 'Software Engineer (Python)',\n",
       " 'Interpreter',\n",
       " 'Architect',\n",
       " 'Meteorologist',\n",
       " 'Audiological scientist',\n",
       " 'English as a second language teacher',\n",
       " 'Surgeon',\n",
       " 'Equities trader',\n",
       " 'Newspaper journalist',\n",
       " 'Materials engineer',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Product/process development scientist',\n",
       " 'Scientist, research (maths)',\n",
       " 'Ecologist',\n",
       " 'Materials engineer',\n",
       " 'Historic buildings inspector/conservation officer',\n",
       " 'Data scientist',\n",
       " 'Psychiatrist',\n",
       " 'Structural engineer',\n",
       " 'Immigration officer',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Neurosurgeon',\n",
       " 'Broadcast engineer',\n",
       " 'Make',\n",
       " 'Nurse, adult',\n",
       " 'Air broker',\n",
       " 'Editor, film/video',\n",
       " 'Production assistant, radio',\n",
       " 'Engineer, communications',\n",
       " 'Sales executive',\n",
       " 'Software Developer (Python)',\n",
       " 'Futures trader',\n",
       " 'Tour manager',\n",
       " 'Cytogeneticist',\n",
       " 'Designer, multimedia',\n",
       " 'Trade union research officer',\n",
       " 'Chemist, analytical',\n",
       " 'Programmer, multimedia',\n",
       " 'Engineer, broadcasting (operations)',\n",
       " 'Teacher, primary school',\n",
       " 'Python Developer',\n",
       " 'Manufacturing systems engineer',\n",
       " 'Producer, television/film/video',\n",
       " 'Scientist, forensic',\n",
       " 'Bonds trader',\n",
       " 'Editorial assistant',\n",
       " 'Photographer',\n",
       " 'Retail banker',\n",
       " 'Jewellery designer',\n",
       " 'Ophthalmologist',\n",
       " 'Back-End Web Developer (Python, Django)',\n",
       " 'Licensed conveyancer',\n",
       " 'Futures trader',\n",
       " 'Counselling psychologist',\n",
       " 'Insurance underwriter',\n",
       " 'Engineer, automotive',\n",
       " 'Producer, radio',\n",
       " 'Dispensing optician',\n",
       " 'Designer, fashion/clothing',\n",
       " 'Chartered loss adjuster',\n",
       " 'Back-End Web Developer (Python, Django)',\n",
       " 'Forest/woodland manager',\n",
       " 'Clinical cytogeneticist',\n",
       " 'Print production planner',\n",
       " 'Systems developer',\n",
       " 'Graphic designer',\n",
       " 'Writer',\n",
       " 'Field seismologist',\n",
       " 'Chief Strategy Officer',\n",
       " 'Air cabin crew',\n",
       " 'Python Programmer (Entry-Level)',\n",
       " 'Warden/ranger',\n",
       " 'Sports therapist',\n",
       " 'Arts development officer',\n",
       " 'Printmaker',\n",
       " 'Health and safety adviser',\n",
       " 'Manufacturing systems engineer',\n",
       " 'Programmer, applications',\n",
       " 'Medical physicist',\n",
       " 'Media planner',\n",
       " 'Software Developer (Python)',\n",
       " 'Surveyor, land/geomatics',\n",
       " 'Legal executive',\n",
       " 'Librarian, academic',\n",
       " 'Barrister',\n",
       " 'Museum/gallery exhibitions officer',\n",
       " 'Radiographer, diagnostic',\n",
       " 'Database administrator',\n",
       " 'Furniture designer',\n",
       " 'Ship broker']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull all titles\n",
    "all_titles = soup.findAll('h2')\n",
    "\n",
    "# Create list of all titles as text\n",
    "job_title = [] #Don't know why I can't use a list comprehension for this - it returns all <none>...\n",
    "\n",
    "for x in all_titles:\n",
    "    job_title.append(x.text)\n",
    "    \n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get companies, locations, and posting dates for each job into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Payne, Roberts and Davis',\n",
       " 'Vasquez-Davidson',\n",
       " 'Jackson, Chambers and Levy',\n",
       " 'Savage-Bradley',\n",
       " 'Ramirez Inc',\n",
       " 'Rogers-Yates',\n",
       " 'Kramer-Klein',\n",
       " 'Meyers-Johnson',\n",
       " 'Hughes-Williams',\n",
       " 'Jones, Williams and Villa',\n",
       " 'Garcia PLC',\n",
       " 'Gregory and Sons',\n",
       " 'Clark, Garcia and Sosa',\n",
       " 'Bush PLC',\n",
       " 'Salazar-Meyers',\n",
       " 'Parker, Murphy and Brooks',\n",
       " 'Cruz-Brown',\n",
       " 'Macdonald-Ferguson',\n",
       " 'Williams, Peterson and Rojas',\n",
       " 'Smith and Sons',\n",
       " 'Moss, Duncan and Allen',\n",
       " 'Gomez-Carroll',\n",
       " 'Manning, Welch and Herring',\n",
       " 'Lee, Gutierrez and Brown',\n",
       " 'Davis, Serrano and Cook',\n",
       " 'Smith LLC',\n",
       " 'Thomas Group',\n",
       " 'Silva-King',\n",
       " 'Pierce-Long',\n",
       " 'Walker-Simpson',\n",
       " 'Cooper and Sons',\n",
       " 'Donovan, Gonzalez and Figueroa',\n",
       " 'Morgan, Butler and Bennett',\n",
       " 'Snyder-Lee',\n",
       " 'Harris PLC',\n",
       " 'Washington PLC',\n",
       " 'Brown, Price and Campbell',\n",
       " 'Mcgee PLC',\n",
       " 'Dixon Inc',\n",
       " 'Thompson, Sheppard and Ward',\n",
       " 'Adams-Brewer',\n",
       " 'Schneider-Brady',\n",
       " 'Gonzales-Frank',\n",
       " 'Smith-Wong',\n",
       " 'Pierce-Herrera',\n",
       " 'Aguilar, Rivera and Quinn',\n",
       " 'Lowe, Barnes and Thomas',\n",
       " 'Lewis, Gonzalez and Vasquez',\n",
       " 'Taylor PLC',\n",
       " 'Oliver, Jones and Ramirez',\n",
       " 'Rivera and Sons',\n",
       " 'Garcia PLC',\n",
       " 'Johnson, Wells and Kramer',\n",
       " 'Gonzalez LLC',\n",
       " 'Morgan, White and Macdonald',\n",
       " 'Robinson-Fitzpatrick',\n",
       " 'Waters, Wilson and Hoover',\n",
       " 'Hill LLC',\n",
       " 'Li-Gregory',\n",
       " 'Fisher, Ryan and Coleman',\n",
       " 'Stewart-Alexander',\n",
       " 'Abbott and Sons',\n",
       " 'Bryant, Santana and Davenport',\n",
       " 'Smith PLC',\n",
       " 'Patterson-Singh',\n",
       " 'Martinez-Berry',\n",
       " 'May, Taylor and Fisher',\n",
       " 'Bailey, Owen and Thompson',\n",
       " 'Vasquez Ltd',\n",
       " 'Leblanc LLC',\n",
       " 'Jackson, Ali and Mckee',\n",
       " 'Blankenship, Knight and Powell',\n",
       " 'Patton, Haynes and Jones',\n",
       " 'Wood Inc',\n",
       " 'Collins Group',\n",
       " 'Flores-Nelson',\n",
       " 'Mitchell, Jones and Olson',\n",
       " 'Howard Group',\n",
       " 'Kramer-Edwards',\n",
       " 'Berry-Houston',\n",
       " 'Mathews Inc',\n",
       " 'Riley-Johnson',\n",
       " 'Spencer and Sons',\n",
       " 'Camacho-Sanchez',\n",
       " 'Oliver and Sons',\n",
       " 'Eaton PLC',\n",
       " 'Stanley-Frederick',\n",
       " 'Bradley LLC',\n",
       " 'Parker, Goodwin and Zavala',\n",
       " 'Kim-Miles',\n",
       " 'Moreno-Rodriguez',\n",
       " 'Brown-Ortiz',\n",
       " 'Hartman PLC',\n",
       " 'Brooks Inc',\n",
       " 'Washington-Castillo',\n",
       " 'Nguyen, Yoder and Petty',\n",
       " 'Holder LLC',\n",
       " 'Yates-Ferguson',\n",
       " 'Ortega-Lawrence',\n",
       " 'Fuentes, Walls and Castro']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_companies = soup.findAll('h3')\n",
    "\n",
    "company = []\n",
    "\n",
    "for x in all_companies:\n",
    "    company.append(x.text)\n",
    "    \n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stewartbury, AA',\n",
       " 'Christopherville, AA',\n",
       " 'Port Ericaburgh, AA',\n",
       " 'East Seanview, AP',\n",
       " 'North Jamieview, AP',\n",
       " 'Davidville, AP',\n",
       " 'South Christopher, AE',\n",
       " 'Port Jonathan, AE',\n",
       " 'Osbornetown, AE',\n",
       " 'Scotttown, AP',\n",
       " 'Ericberg, AE',\n",
       " 'Ramireztown, AE',\n",
       " 'Figueroaview, AA',\n",
       " 'Kelseystad, AA',\n",
       " 'Williamsburgh, AE',\n",
       " 'Mitchellburgh, AE',\n",
       " 'West Jessicabury, AA',\n",
       " 'Maloneshire, AE',\n",
       " 'Johnsonton, AA',\n",
       " 'South Davidtown, AP',\n",
       " 'Port Sara, AE',\n",
       " 'Marktown, AA',\n",
       " 'Laurenland, AE',\n",
       " 'Lauraton, AP',\n",
       " 'South Tammyberg, AP',\n",
       " 'North Brandonville, AP',\n",
       " 'Port Robertfurt, AA',\n",
       " 'Burnettbury, AE',\n",
       " 'Herbertside, AA',\n",
       " 'Christopherport, AP',\n",
       " 'West Victor, AE',\n",
       " 'Port Aaron, AP',\n",
       " 'Loribury, AA',\n",
       " 'Angelastad, AP',\n",
       " 'Larrytown, AE',\n",
       " 'West Colin, AP',\n",
       " 'West Stephanie, AP',\n",
       " 'Laurentown, AP',\n",
       " 'Wrightberg, AP',\n",
       " 'Alberttown, AE',\n",
       " 'Brockburgh, AE',\n",
       " 'North Jason, AE',\n",
       " 'Arnoldhaven, AE',\n",
       " 'Lake Destiny, AP',\n",
       " 'South Timothyburgh, AP',\n",
       " 'New Jimmyton, AE',\n",
       " 'New Lucasbury, AP',\n",
       " 'Port Cory, AE',\n",
       " 'Gileston, AA',\n",
       " 'Cindyshire, AA',\n",
       " 'East Michaelfort, AA',\n",
       " 'Joybury, AE',\n",
       " 'Emmatown, AE',\n",
       " 'Colehaven, AP',\n",
       " 'Port Coryton, AE',\n",
       " 'Amyborough, AA',\n",
       " 'Reynoldsville, AA',\n",
       " 'Port Billy, AP',\n",
       " 'Adamburgh, AA',\n",
       " 'Wilsonmouth, AA',\n",
       " 'South Kimberly, AA',\n",
       " 'Benjaminland, AP',\n",
       " 'Zacharyport, AA',\n",
       " 'Port Devonville, AE',\n",
       " 'East Thomas, AE',\n",
       " 'New Jeffrey, AP',\n",
       " 'Davidside, AA',\n",
       " 'Jamesville, AA',\n",
       " 'New Kelly, AP',\n",
       " 'Lake Antonio, AA',\n",
       " 'New Elizabethside, AA',\n",
       " 'Millsbury, AE',\n",
       " 'Lloydton, AP',\n",
       " 'Port Jeremy, AA',\n",
       " 'New Elizabethtown, AA',\n",
       " 'Charlesstad, AE',\n",
       " 'Josephbury, AE',\n",
       " 'Seanfurt, AA',\n",
       " 'Williambury, AA',\n",
       " 'South Jorgeside, AP',\n",
       " 'Robertborough, AP',\n",
       " 'South Saratown, AP',\n",
       " 'Hullview, AA',\n",
       " 'Philipland, AP',\n",
       " 'North Patty, AE',\n",
       " 'North Stephen, AE',\n",
       " 'Stevensland, AP',\n",
       " 'Reyesstad, AE',\n",
       " 'Bellberg, AP',\n",
       " 'North Johnland, AE',\n",
       " 'Martinezburgh, AE',\n",
       " 'Joshuatown, AE',\n",
       " 'West Ericstad, AA',\n",
       " 'Tuckertown, AE',\n",
       " 'Perezton, AE',\n",
       " 'Lake Abigail, AE',\n",
       " 'Jacobshire, AP',\n",
       " 'Port Susan, AE',\n",
       " 'North Tiffany, AA',\n",
       " 'Michelleville, AP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_locations = soup.findAll('p')\n",
    "# There are two <p> tags showing up here, so the list should only inlucde every other entry. (Also need to strip out white space)\n",
    "\n",
    "location = []\n",
    "\n",
    "for index in range(1, len(all_locations), 2):\n",
    "     location.append(all_locations[index].text.strip())\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08',\n",
       " '2021-04-08']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_postings = soup.findAll('time')\n",
    "\n",
    "post_date = []\n",
    "for x in all_postings:\n",
    "    post_date.append(x.text)\n",
    "post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                     company              location  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
       "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
       "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
       "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
       "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
       "\n",
       "  posting_date  \n",
       "0   2021-04-08  \n",
       "1   2021-04-08  \n",
       "2   2021-04-08  \n",
       "3   2021-04-08  \n",
       "4   2021-04-08  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.DataFrame({'title': job_title, 'company': company, 'location': location, 'posting_date': post_date})\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column that includes the link to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title                     company              location  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
       "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
       "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
       "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
       "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
       "\n",
       "  posting_date                                               link  \n",
       "0   2021-04-08  https://realpython.github.io/fake-jobs/jobs/se...  \n",
       "1   2021-04-08  https://realpython.github.io/fake-jobs/jobs/en...  \n",
       "2   2021-04-08  https://realpython.github.io/fake-jobs/jobs/le...  \n",
       "3   2021-04-08  https://realpython.github.io/fake-jobs/jobs/fi...  \n",
       "4   2021-04-08  https://realpython.github.io/fake-jobs/jobs/pr...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_links = soup.findAll('a')\n",
    "# Also need to filter out the duplicate URL that appears every other entry.\n",
    "link = []\n",
    "\n",
    "for index in range(1, len(apply_links), 2):\n",
    "     link.append(apply_links[index].get('href'))\n",
    "     \n",
    "link\n",
    "\n",
    "jobs['link'] = link\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternate Solution** build the URLs from scratch.\n",
    "\n",
    "The URL strings follow the following convention:\n",
    "- https :// realpython.github.io / fake-jobs / jobs / <job_title_lowercase> <next_counter>.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
